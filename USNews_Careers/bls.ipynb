{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "\n",
    "# Set up the WebDriver (choose your preferred browser)\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "\n",
    "\n",
    "# Add other desired options here\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get('https://www.bls.gov/ooh/home.htm')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up the WebDriver (choose your preferred browser)\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "options = webdriver.ChromeOptions()\n",
    "# Add other desired options here\n",
    "\n",
    "# Start the WebDriver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Open the webpage\n",
    "driver.get('https://www.bls.gov/ooh/home.htm')\n",
    "\n",
    "# Wait for some time to ensure the page is fully loaded\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find all <a> tags with href containing '/ooh/'\n",
    "links = soup.find_all('a', href=lambda href: href and '/ooh/' in href)\n",
    "\n",
    "# Extract the href and text of each link\n",
    "link_data = []\n",
    "for link in links:\n",
    "    link_data.append({'href': link['href'], 'text': link.text.strip()})\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame\n",
    "df = pd.DataFrame(link_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('links.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
