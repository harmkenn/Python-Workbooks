{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: Chrome failed to start: exited normally.\n  (session not created: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /home/gitpod/.cache/selenium/chrome/linux64/123.0.6312.105/chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\nStacktrace:\n#0 0x55d49d9b6873 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x77a872)\n#1 0x55d49d6ac8c6 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4708c5)\n#2 0x55d49d6e0d34 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4a4d33)\n#3 0x55d49d6dcd3d (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4a0d3c)\n#4 0x55d49d725aed (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4e9aec)\n#5 0x55d49d719343 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4dd342)\n#6 0x55d49d6ea593 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4ae592)\n#7 0x55d49d6eaf5e (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4aef5d)\n#8 0x55d49d97a85b (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x73e85a)\n#9 0x55d49d97e7b5 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x7427b4)\n#10 0x55d49d968581 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x72c580)\n#11 0x55d49d97f342 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x743341)\n#12 0x55d49d94d88f (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x71188e)\n#13 0x55d49d9a5738 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x769737)\n#14 0x55d49d9a590b (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x76990a)\n#15 0x55d49d9b59c4 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x7799c3)\n#16 0x7f8585bdbac3 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/usr/lib/x86_64-linux-gnu/libc.so.6+0x94ac2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Python-Workbooks/USNews_Careers/bls.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://harmkenn-pythonworkbook-9ars0whgk0k.ws-eu110.gitpod.io/workspace/Python-Workbooks/USNews_Careers/bls.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m options \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mChromeOptions()\n\u001b[1;32m     <a href='vscode-notebook-cell://harmkenn-pythonworkbook-9ars0whgk0k.ws-eu110.gitpod.io/workspace/Python-Workbooks/USNews_Careers/bls.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Add other desired options here\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://harmkenn-pythonworkbook-9ars0whgk0k.ws-eu110.gitpod.io/workspace/Python-Workbooks/USNews_Careers/bls.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m     <a href='vscode-notebook-cell://harmkenn-pythonworkbook-9ars0whgk0k.ws-eu110.gitpod.io/workspace/Python-Workbooks/USNews_Careers/bls.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m driver\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mhttps://www.bls.gov/ooh/home.htm\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://harmkenn-pythonworkbook-9ars0whgk0k.ws-eu110.gitpod.io/workspace/Python-Workbooks/USNews_Careers/bls.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m driver\u001b[39m.\u001b[39mmaximize_window()\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[39m=\u001b[39m service \u001b[39mif\u001b[39;00m service \u001b[39melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[39m=\u001b[39m options \u001b[39mif\u001b[39;00m options \u001b[39melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     46\u001b[0m     browser_name\u001b[39m=\u001b[39;49mDesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m\"\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     47\u001b[0m     vendor_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     48\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m     49\u001b[0m     service\u001b[39m=\u001b[39;49mservice,\n\u001b[1;32m     50\u001b[0m     keep_alive\u001b[39m=\u001b[39;49mkeep_alive,\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py:61\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     52\u001b[0m executor \u001b[39m=\u001b[39m ChromiumRemoteConnection(\n\u001b[1;32m     53\u001b[0m     remote_server_addr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mservice_url,\n\u001b[1;32m     54\u001b[0m     browser_name\u001b[39m=\u001b[39mbrowser_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     ignore_proxy\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(command_executor\u001b[39m=\u001b[39;49mexecutor, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquit()\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:208\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_authenticator_id \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_client()\n\u001b[0;32m--> 208\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_session(capabilities)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:292\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[39m:Args:\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m - capabilities - a capabilities dict to start the session with.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    291\u001b[0m caps \u001b[39m=\u001b[39m _create_caps(capabilities)\n\u001b[0;32m--> 292\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mNEW_SESSION, caps)[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    293\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcaps \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcapabilities\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    348\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mSessionNotCreatedException\u001b[0m: Message: session not created: Chrome failed to start: exited normally.\n  (session not created: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /home/gitpod/.cache/selenium/chrome/linux64/123.0.6312.105/chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\nStacktrace:\n#0 0x55d49d9b6873 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x77a872)\n#1 0x55d49d6ac8c6 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4708c5)\n#2 0x55d49d6e0d34 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4a4d33)\n#3 0x55d49d6dcd3d (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4a0d3c)\n#4 0x55d49d725aed (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4e9aec)\n#5 0x55d49d719343 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4dd342)\n#6 0x55d49d6ea593 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4ae592)\n#7 0x55d49d6eaf5e (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x4aef5d)\n#8 0x55d49d97a85b (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x73e85a)\n#9 0x55d49d97e7b5 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x7427b4)\n#10 0x55d49d968581 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x72c580)\n#11 0x55d49d97f342 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x743341)\n#12 0x55d49d94d88f (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x71188e)\n#13 0x55d49d9a5738 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x769737)\n#14 0x55d49d9a590b (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x76990a)\n#15 0x55d49d9b59c4 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/home/gitpod/.cache/selenium/chromedriver/linux64/123.0.6312.105/chromedriver+0x7799c3)\n#16 0x7f8585bdbac3 (/run/containerd/io.containerd.runtime.v2.task/k8s.io/dd126ea700c12b0e3202ccf1fda47cb383ae26e65d9b82905d5d0eadd9efd294/rootfs/usr/lib/x86_64-linux-gnu/libc.so.6+0x94ac2)\n"
     ]
    }
   ],
>>>>>>> 4ea682a (up)
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "\n",
    "# Set up the WebDriver (choose your preferred browser)\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "\n",
    "\n",
    "# Add other desired options here\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get('https://www.bls.gov/ooh/home.htm')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up the WebDriver (choose your preferred browser)\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "options = webdriver.ChromeOptions()\n",
    "# Add other desired options here\n",
    "\n",
    "# Start the WebDriver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Open the webpage\n",
    "driver.get('https://www.bls.gov/ooh/home.htm')\n",
    "\n",
    "# Wait for some time to ensure the page is fully loaded\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find all <a> tags with href containing '/ooh/'\n",
    "links = soup.find_all('a', href=lambda href: href and '/ooh/' in href)\n",
    "\n",
    "# Extract the href and text of each link\n",
    "link_data = []\n",
    "for link in links:\n",
    "    link_data.append({'href': link['href'], 'text': link.text.strip()})\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame\n",
    "df = pd.DataFrame(link_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_links = pd.read_csv('links.csv')\n",
    "pd_links = pd_links[~pd_links['text'].str.contains('view', na=False)]\n",
    "# Drop rows with index from 0 to 9\n",
    "pd_links.drop(index=pd_links.index[:9], inplace=True)\n",
    "\n",
    "# Drop rows with index from 700 to 750\n",
    "pd_links.drop(index=pd_links.index[358:], inplace=True)\n",
    "# Add a new column named 'type' and set initial value as 'occupation'\n",
    "pd_links['type'] = 'occupation'\n",
    "\n",
    "# Mark the first 23 rows as 'group' in the 'type' column\n",
    "pd_links.loc[:33, 'type'] = 'group'\n",
    "pd_links['grp'] = pd_links['href'].str.split('/').str[2]\n",
    "\n",
    "vl = pd_links.iloc[:25, [1, 3]].copy()\n",
    "\n",
    "pd_links = pd_links.merge(vl, on='grp', how='left')\n",
    "\n",
    "pd_links.rename(columns={'text_y': 'group'}, inplace=True)\n",
    "pd_links.rename(columns={'text_x': 'Occupation'}, inplace=True)\n",
    "\n",
    "pd_links_sorted = pd_links.sort_values(by=['group', 'type', 'Occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "pd_links.to_csv('BLSdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "BLSdata = pd.read_csv('BLSdata.csv')\n",
    "OCCdata =  BLSdata[BLSdata['type']=='occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "for url in OCCdata['href']:\n",
    "    page = f'https://www.bls.gov{url}'\n",
    "    response = requests.get(page)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Create empty lists to store extracted data\n",
    "median_pay = []\n",
    "hourly_pay = []\n",
    "\n",
    "for url in OCCdata['href']:\n",
    "    page = f'https://www.bls.gov{url}'\n",
    "    response = requests.get(page)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all <td> elements\n",
    "    td_elements = soup.find_all('td')\n",
    "    found = False\n",
    "    \n",
    "    # Iterate through all <td> elements to find median pay\n",
    "    for td_element in td_elements:\n",
    "        if \"Median Pay\" in td_element.text:\n",
    "            found = True\n",
    "            data = td_element.text.strip()\n",
    "            median_pay.append(data)\n",
    "\n",
    "            # Extract hourly pay if available\n",
    "            br_element = td_element.find_next('br')\n",
    "            if br_element:\n",
    "                hourly_pay_text = br_element.next_sibling.strip()\n",
    "                hourly_pay.append(hourly_pay_text)\n",
    "            else:\n",
    "                hourly_pay.append(None)\n",
    "            break\n",
    "    \n",
    "    # If median pay is not found, append None for both median_pay and hourly_pay\n",
    "    if not found:\n",
    "        median_pay.append(None)\n",
    "        hourly_pay.append(None)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "data = {\n",
    "    'Median Pay': median_pay,\n",
    "    'Hourly Pay': hourly_pay\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Now you have a DataFrame containing the extracted data\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame to store extracted data (modify column names as needed)\n",
    "job_data_df = pd.DataFrame(columns=['URL', 'Median Pay', 'Education', 'Experience'])\n",
    "\n",
    "for url in OCCdata['href']:\n",
    "  page = f'https://www.bls.gov{url}'\n",
    "  response = requests.get(page)\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "  # Extract data\n",
    "  job_data = {}\n",
    "  job_data['URL'] = url  # Store URL for reference\n",
    "\n",
    "  # Target table row for Median Pay\n",
    "  table_row = soup.find('tr', {'class': 'quickfacts'})  # Look for rows with class 'quickfacts'\n",
    "  if table_row:\n",
    "    data_cell = table_row.find('th', text=lambda text: text and text.startswith('2022 Median Pay'))  # Find header containing '2022 Median Pay'\n",
    "    if data_cell:\n",
    "      # Get the text content within the table cell, excluding child elements (anchor tag)\n",
    "      job_data['Median Pay'] = data_cell.text.strip().split('\\n')[0]  # Get first line, remove whitespace\n",
    "    else:\n",
    "      job_data['Median Pay'] = \"\"  # Assign empty string if header not found\n",
    "\n",
    "  # Target table row for Education (similar approach)\n",
    "  table_row = soup.find('tr', {'class': 'quickfacts'})\n",
    "  if table_row:\n",
    "    data_cell = table_row.find('th', text=lambda text: text and text.startswith('Typical Entry-Level Education'))\n",
    "    if data_cell:\n",
    "      job_data['Education'] = data_cell.text.strip().split('\\n')[0]  # Get first line, remove whitespace\n",
    "    else:\n",
    "      job_data['Education'] = \"\"\n",
    "\n",
    "  # Target table row for Experience (similar approach)\n",
    "  table_row = soup.find('tr', {'class': 'quickfacts'})\n",
    "  if table_row:\n",
    "    data_cell = table_row.find('th', text=lambda text: text and text.startswith('Work Experience'))\n",
    "    if data_cell:\n",
    "      job_data['Experience'] = data_cell.text.strip().split('\\n')[0]  # Get first line, remove whitespace\n",
    "    else:\n",
    "      job_data['Experience'] = \"\"\n",
    "\n",
    "  # ... Extract and store other desired data points ...\n",
    "\n",
    "  # Append data to DataFrame\n",
    "  job_data_df = pd.concat([job_data_df, pd.DataFrame([job_data])], ignore_index=True)\n",
    "\n",
    "print(job_data_df)  # Print the DataFrame containing extracted data (may include NaN for missing data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame to store extracted data\n",
    "job_data_df = pd.DataFrame(columns=['URL', 'Median Pay', 'Education', 'Experience'])\n",
    "\n",
    "# Headers to mimic a legitimate browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "\n",
    "for url in OCCdata['href']:\n",
    "    page = f'https://www.bls.gov{url}'\n",
    "    response = requests.get(page)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Extract data\n",
    "        job_data = {'URL': url}\n",
    "\n",
    "        # Find all rows in the table\n",
    "        table_rows = soup.find_all('tr')\n",
    "\n",
    "        for row in table_rows:\n",
    "            header = row.find('th')\n",
    "            if header:\n",
    "                header_text = header.get_text(strip=True)\n",
    "                if header_text.startswith('2022 Median Pay'):\n",
    "                    job_data['Median Pay'] = row.find('td').get_text(strip=True)\n",
    "                elif header_text.startswith('Typical Entry-Level Education'):\n",
    "                    job_data['Education'] = row.find('td').get_text(strip=True)\n",
    "                elif header_text.startswith('Work Experience'):\n",
    "                    job_data['Experience'] = row.find('td').get_text(strip=True)\n",
    "\n",
    "        # Append data to DataFrame\n",
    "        job_data_df = job_data_df.append(job_data, ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {page}. Status code: {response.status_code}\")\n",
    "\n",
    "print(job_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store extracted data dictionaries\n",
    "job_data_list = []\n",
    "\n",
    "for url in OCCdata['href']:\n",
    "  page = f'https://www.bls.gov{url}'\n",
    "  response = requests.get(page)\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "  job_data = {}\n",
    "  job_data['URL'] = url  # Store URL for reference\n",
    "\n",
    "  # Extract data from all 'quickfacts' rows\n",
    "  for table_row in soup.find_all('tr', {'class': 'quickfacts'}):\n",
    "\n",
    "    # Median Pay\n",
    "    if data_cell := table_row.find('th', text=\"2022 Median Pay\"):\n",
    "      job_data['Median Pay'] = data_cell.text.strip().split('\\n')[0]\n",
    "\n",
    "    # Education\n",
    "    if data_cell := table_row.find('th', text=\"Typical Entry-Level Education\"):\n",
    "      job_data['Education'] = data_cell.text.strip().split('\\n')[0]\n",
    "\n",
    "    # Experience\n",
    "    if data_cell := table_row.find('th', text=\"Work Experience in a Related Occupation\"):\n",
    "      job_data['Experience'] = data_cell.text.strip().split('\\n')[0]\n",
    "\n",
    "  # Append job_data dictionary to the list\n",
    "  job_data_list.append(job_data)\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "job_data_df = pd.DataFrame(job_data_list)\n",
    "\n",
    "print(job_data_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
