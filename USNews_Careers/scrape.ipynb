{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://money.usnews.com/careers/best-jobs/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Career]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Open the HTML file and read its contents\n",
    "with open('usnews.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all job listings\n",
    "#<h2 class=\"Heading-sc-1w5xk2o-0 kSaPXj\"><a href=\"https://money.usnews.com/careers/best-jobs/accountant\">Accountant</a></h2>\n",
    "job_listings = soup.find_all('h2', class_='Heading-sc-1w5xk2o-0 kSaPXj')\n",
    "\n",
    "# Initialize lists to store data\n",
    "job_titles = []\n",
    "median_salaries = []\n",
    "job_scores = []\n",
    "job_urls = []\n",
    "\n",
    "# Find all job listings\n",
    "job_listings = soup.find_all('h2', class_='Heading-sc-1w5xk2o-0 kSaPXj')\n",
    "\n",
    "# Find all median salaries\n",
    "median_salary_elements = soup.find_all('div', class_='Row__StyledRow-sc-1tzw0za-0.bLXvOT')\n",
    "\n",
    "# Find all job scores\n",
    "job_score_elements = soup.find_all('div', class_='Row__StyledRow-sc-1tzw0za-0.kTPvuu')\n",
    "\n",
    "# Find all job URLs\n",
    "job_url_elements = soup.find_all('a', class_='card-image-container')\n",
    "\n",
    "# Extract job titles, median salaries, job scores, and URLs\n",
    "for job, salary, score, url in zip(job_listings, median_salary_elements, job_score_elements, job_url_elements):\n",
    "    job_titles.append(job.text.strip())\n",
    "    median_salaries.append(salary.text.strip())\n",
    "    job_scores.append(score.text.strip())\n",
    "    job_urls.append(url['href'])  # Extract URL from 'href' attribute\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Career': job_titles,\n",
    "    #'URL': job_urls\n",
    "    #'Median Salary': salaries,\n",
    "    #'Job Score': scores\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_next_sibling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Extract QuickStats data\u001b[39;00m\n\u001b[0;32m     28\u001b[0m quickstats \u001b[38;5;241m=\u001b[39m code_chunk\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdl\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuickStats-sc-6jc7cd-0 eqdcBH\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m projected_job \u001b[38;5;241m=\u001b[39m \u001b[43mquickstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProjected Jobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_next_sibling\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     30\u001b[0m median_salary \u001b[38;5;241m=\u001b[39m quickstats\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m, string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedian Salary\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind_next_sibling(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     31\u001b[0m education \u001b[38;5;241m=\u001b[39m quickstats\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m, string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation Needed\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind_next_sibling(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_next_sibling'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Open the HTML file and read its contents\n",
    "with open('usnews.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Initialize a list to store career titles\n",
    "career_titles = []\n",
    "career_urls = []\n",
    "projected_jobs = []\n",
    "median_salaries = []\n",
    "education_needed = []\n",
    "\n",
    "# Find all code chunks containing career titles\n",
    "code_chunks = soup.find_all('div', class_='DetailCardJob__Layout-csuvu4-0')\n",
    "\n",
    "# Extract career titles from each code chunk\n",
    "for code_chunk in code_chunks:\n",
    "    # Extract career title and URL\n",
    "    career_title = code_chunk.find('h2', class_='Heading-sc-1w5xk2o-0 kSaPXj').text.strip()\n",
    "    career_url = code_chunk.find('a', class_='card-base-link')['href']\n",
    "    \n",
    "    # Extract QuickStats data\n",
    "    quickstats = code_chunk.find('dl', class_='QuickStats-sc-6jc7cd-0 eqdcBH')\n",
    "    projected_job = quickstats.find('dd', string='Projected Jobs').find_next_sibling('dd').text.strip()\n",
    "    median_salary = quickstats.find('dd', string='Median Salary').find_next_sibling('dd').text.strip()\n",
    "    education = quickstats.find('dd', string='Education Needed').find_next_sibling('dd').text.strip()\n",
    "    \n",
    "    # Append data to lists\n",
    "    career_titles.append(career_title)\n",
    "    career_urls.append(career_url)\n",
    "    projected_jobs.append(projected_job)\n",
    "    median_salaries.append(median_salary)\n",
    "    education_needed.append(education)\n",
    "\n",
    "# Create a pandas DataFrame with career titles\n",
    "df = pd.DataFrame({\n",
    "    'Career Title': career_titles,\n",
    "    'URL': career_urls,\n",
    "    'Projected Jobs': projected_jobs,\n",
    "    'Median Salary': median_salaries,\n",
    "    'Education Needed': education_needed\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Career Title  \\\n",
      "0                                Accountant   \n",
      "1                                     Actor   \n",
      "2                                   Actuary   \n",
      "3                  Administrative Assistant   \n",
      "4                          Anesthesiologist   \n",
      "..                                      ...   \n",
      "185                            Veterinarian   \n",
      "186  Veterinary Technologist and Technician   \n",
      "187                     Waiter and Waitress   \n",
      "188                           Web Developer   \n",
      "189                 Wind Turbine Technician   \n",
      "\n",
      "                                                   URL Projected Jobs  \\\n",
      "0    https://money.usnews.com/careers/best-jobs/acc...           None   \n",
      "1     https://money.usnews.com/careers/best-jobs/actor           None   \n",
      "2    https://money.usnews.com/careers/best-jobs/act...           None   \n",
      "3    https://money.usnews.com/careers/best-jobs/adm...           None   \n",
      "4    https://money.usnews.com/careers/best-jobs/ane...           None   \n",
      "..                                                 ...            ...   \n",
      "185  https://money.usnews.com/careers/best-jobs/vet...           None   \n",
      "186  https://money.usnews.com/careers/best-jobs/vet...           None   \n",
      "187  https://money.usnews.com/careers/best-jobs/wai...           None   \n",
      "188  https://money.usnews.com/careers/best-jobs/web...           None   \n",
      "189  https://money.usnews.com/careers/best-jobs/win...           None   \n",
      "\n",
      "    Median Salary Education Needed  \n",
      "0            None             None  \n",
      "1            None             None  \n",
      "2            None             None  \n",
      "3            None             None  \n",
      "4            None             None  \n",
      "..            ...              ...  \n",
      "185          None             None  \n",
      "186          None             None  \n",
      "187          None             None  \n",
      "188          None             None  \n",
      "189          None             None  \n",
      "\n",
      "[190 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Open the HTML file and read its contents\n",
    "with open('usnews.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Initialize lists to store data\n",
    "career_titles = []\n",
    "career_urls = []\n",
    "projected_jobs = []\n",
    "median_salaries = []\n",
    "education_needed = []\n",
    "\n",
    "# Find all code chunks containing career titles, URLs, and QuickStats\n",
    "code_chunks = soup.find_all('div', class_='DetailCardJob__Layout-csuvu4-0')\n",
    "\n",
    "# Extract data from each code chunk\n",
    "for code_chunk in code_chunks:\n",
    "    # Extract career title and URL\n",
    "    career_title = code_chunk.find('h2', class_='Heading-sc-1w5xk2o-0 kSaPXj').text.strip()\n",
    "    career_url = code_chunk.find('a', class_='card-base-link')['href']\n",
    "    \n",
    "    # Extract QuickStats data\n",
    "    quickstats = code_chunk.find('dl', class_='QuickStats-sc-6jc7cd-0 eqdcBH')\n",
    "    \n",
    "    # Find and extract projected jobs\n",
    "    projected_job_tag = quickstats.find('dd', string='Projected Jobs')\n",
    "    projected_job = projected_job_tag.find_next_sibling('dd').text.strip() if projected_job_tag else None\n",
    "    \n",
    "    # Find and extract median salary\n",
    "    median_salary_tag = quickstats.find('dd', string='Median Salary')\n",
    "    median_salary = median_salary_tag.find_next_sibling('dd').text.strip() if median_salary_tag else None\n",
    "    \n",
    "    # Find and extract education needed\n",
    "    education_tag = quickstats.find('dd', string='Education Needed')\n",
    "    education = education_tag.find_next_sibling('dd').text.strip() if education_tag else None\n",
    "    \n",
    "    # Append data to lists\n",
    "    career_titles.append(career_title)\n",
    "    career_urls.append(career_url)\n",
    "    projected_jobs.append(projected_job)\n",
    "    median_salaries.append(median_salary)\n",
    "    education_needed.append(education)\n",
    "\n",
    "# Create a pandas DataFrame with all the extracted data\n",
    "df = pd.DataFrame({\n",
    "    'Career Title': career_titles,\n",
    "    'URL': career_urls,\n",
    "    'Projected Jobs': projected_jobs,\n",
    "    'Median Salary': median_salaries,\n",
    "    'Education Needed': education_needed\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
