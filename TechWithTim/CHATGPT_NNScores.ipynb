{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is an example of python code for creating two outputs in a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Round</th>\n",
       "      <th>Region</th>\n",
       "      <th>Game</th>\n",
       "      <th>AFSeed</th>\n",
       "      <th>AFTeam</th>\n",
       "      <th>AUSeed</th>\n",
       "      <th>AUTeam</th>\n",
       "      <th>Fti</th>\n",
       "      <th>Uti</th>\n",
       "      <th>...</th>\n",
       "      <th>W_y</th>\n",
       "      <th>L_y</th>\n",
       "      <th>Pts_y</th>\n",
       "      <th>Opp_y</th>\n",
       "      <th>MOV_y</th>\n",
       "      <th>SOS_y</th>\n",
       "      <th>OSRS_y</th>\n",
       "      <th>DSRS_y</th>\n",
       "      <th>SRS_y</th>\n",
       "      <th>PASE_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>PI</td>\n",
       "      <td>PI</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>Mount St. Mary's</td>\n",
       "      <td>16</td>\n",
       "      <td>Coppin St.</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>-12.38</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>-14.51</td>\n",
       "      <td>0.241228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>NW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>16</td>\n",
       "      <td>Mount St. Mary's</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>67.7</td>\n",
       "      <td>1.53</td>\n",
       "      <td>-5.12</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>0.493421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>NW</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>9</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>74.1</td>\n",
       "      <td>68.3</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.67</td>\n",
       "      <td>5.81</td>\n",
       "      <td>12.48</td>\n",
       "      <td>0.269165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>NW</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>12</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>62.5</td>\n",
       "      <td>6.82</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.11</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>NW</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Washington St.</td>\n",
       "      <td>13</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>64.9</td>\n",
       "      <td>58.5</td>\n",
       "      <td>6.32</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-7.17</td>\n",
       "      <td>10.78</td>\n",
       "      <td>3.61</td>\n",
       "      <td>-0.116959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Round Region  Game  AFSeed            AFTeam  AUSeed  \\\n",
       "0  2008    PI     PI    -1      16  Mount St. Mary's      16   \n",
       "1  2008     1     NW     1       1    North Carolina      16   \n",
       "2  2008     1     NW     2       8           Indiana       9   \n",
       "3  2008     1     NW     3       5        Notre Dame      12   \n",
       "4  2008     1     NW     4       4    Washington St.      13   \n",
       "\n",
       "             AUTeam  Fti  Uti  ...   W_y   L_y  Pts_y  Opp_y  MOV_y  SOS_y  \\\n",
       "0        Coppin St.    2   65  ...  16.0  21.0   59.8   66.0  -6.24  -6.20   \n",
       "1  Mount St. Mary's    1    2  ...  19.0  15.0   69.2   67.7   1.53  -5.12   \n",
       "2          Arkansas    3    4  ...  23.0  12.0   74.1   68.3   5.74   6.73   \n",
       "3      George Mason    5    6  ...  23.0  11.0   69.3   62.5   6.82  -0.75   \n",
       "4          Winthrop    7    8  ...  22.0  12.0   64.9   58.5   6.32  -1.45   \n",
       "\n",
       "   OSRS_y  DSRS_y  SRS_y    PASE_y  \n",
       "0  -12.38   -2.13 -14.51  0.241228  \n",
       "1   -3.87    0.28  -3.59  0.493421  \n",
       "2    6.67    5.81  12.48  0.269165  \n",
       "3    0.96    5.11   6.07  0.458333  \n",
       "4   -7.17   10.78   3.61 -0.116959  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas dataframe\n",
    "MMStats = pd.read_csv('FUStats.csv')\n",
    "\n",
    "# Divide inputs from outputs\n",
    "X = MMStats.drop(columns=['AFScore','AUScore'])\n",
    "y =  MMStats[['AFScore','AUScore']]\n",
    "\n",
    "X.head()\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "25/25 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.7345   \n",
      "Epoch 2/8\n",
      "25/25 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7345\n",
      "Epoch 3/8\n",
      "25/25 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7345\n",
      "Epoch 4/8\n",
      "25/25 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7345\n",
      "Epoch 5/8\n",
      "25/25 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7345\n",
      "Epoch 6/8\n",
      "25/25 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7345\n",
      "Epoch 7/8\n",
      "25/25 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7345\n",
      "Epoch 8/8\n",
      "25/25 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7345\n",
      "7/7 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7306\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(22, input_shape=(44,), activation='relu'))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "# Predict using the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
