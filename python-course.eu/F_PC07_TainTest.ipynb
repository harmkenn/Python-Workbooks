{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python-course.eu/machine-learning/train-and-test-sets-by-splitting-learn-and-test-data.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 88,  30,  57,  22, 139, 135,   1,  58, 105,  32,  18,   5,  34,\n",
       "        71, 133,   0, 121, 134,  52,  40,  41,  68, 128,  47,  86, 132,\n",
       "       122, 106,  11, 107,  77, 104,   3,  69, 116,  94,  84,  66,  10,\n",
       "         7,  75,  63,  55,  29,  33,  37,  62, 112,  48,  82, 141,  61,\n",
       "       127, 137, 129, 117,  21,  51,  43,  98, 120,  97,  49,  31,  80,\n",
       "       145,  81, 148,  72,  23, 136,  56,  78,  44,  20,  85,  64,  91,\n",
       "        60, 110,  87, 118,  54,  42,  12,  36, 146,  46,  92, 103,  90,\n",
       "        95,  70, 100,  14,   8, 126,   4,  24,  89,  67, 147,   9, 102,\n",
       "        26,  96, 138, 149,  53, 109,  13,  15, 125,  35,  59, 124, 101,\n",
       "        50,   6,  16,  38, 119,   2,  73,  39,  65, 144,  27,  17, 130,\n",
       "       114,  45, 142, 115,  19, 140, 108,  28,  76, 143,  25,  83, 123,\n",
       "       131, 113,  74,  93,  99,  79, 111])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.random.permutation(len(iris.data))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.6 3.  4.1 1.3]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [4.6 3.6 1.  0.2]] [1 0 1 0]\n",
      "[[6.8 2.8 4.8 1.4]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [6.  2.7 5.1 1.6]] [1 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "n_test_samples = 12\n",
    "learnset_data = iris.data[indices[:-n_test_samples]]\n",
    "learnset_labels = iris.target[indices[:-n_test_samples]]\n",
    "testset_data = iris.data[indices[-n_test_samples:]]\n",
    "testset_labels = iris.target[indices[-n_test_samples:]]\n",
    "print(learnset_data[:4], learnset_labels[:4])\n",
    "print(testset_data[:4], testset_labels[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 7 data sets:\n",
      "[[6.1 2.8 4.7 1.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.6 2.9 3.6 1.3]]\n",
      "The corresponding 7 labels:\n",
      "[1 0 2 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "data, labels = iris.data, iris.target\n",
    "\n",
    "res = train_test_split(data, labels, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42)\n",
    "train_data, test_data, train_labels, test_labels = res    \n",
    "\n",
    "n = 7\n",
    "print(f\"The first {n} data sets:\")\n",
    "print(test_data[:7])\n",
    "print(f\"The corresponding {n} labels:\")\n",
    "print(test_labels[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: [33.33333333 33.33333333 33.33333333]\n",
      "Training: [33.33333333 34.16666667 32.5       ]\n",
      "Test: [33.33333333 30.         36.66666667]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('All:', np.bincount(labels) / float(len(labels)) * 100.0)\n",
    "print('Training:', np.bincount(train_labels) / float(len(train_labels)) * 100.0)\n",
    "print('Test:', np.bincount(test_labels) / float(len(test_labels)) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: [33.33333333 33.33333333 33.33333333]\n",
      "Training: [33.33333333 33.33333333 33.33333333]\n",
      "Test: [33.33333333 33.33333333 33.33333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "data, labels = iris.data, iris.target\n",
    "\n",
    "res = train_test_split(data, labels, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42,\n",
    "                       stratify=labels)\n",
    "train_data, test_data, train_labels, test_labels = res \n",
    "\n",
    "print('All:', np.bincount(labels) / float(len(labels)) * 100.0)\n",
    "print('Training:', np.bincount(train_labels) / float(len(train_labels)) * 100.0)\n",
    "print('Test:', np.bincount(test_labels) / float(len(test_labels)) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = np.loadtxt(\"./data/strange_flowers.txt\", delimiter=\" \")\n",
    "data = content[:, :-1]    # cut of the target column\n",
    "labels = content[:, -1]\n",
    "labels.dtype\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: [ 0.         23.89937107 25.78616352 28.93081761 21.3836478 ]\n",
      "Training: [ 0.         23.89937107 25.78616352 28.93081761 21.3836478 ]\n",
      "Test: [ 0.         23.89937107 25.78616352 28.93081761 21.3836478 ]\n"
     ]
    }
   ],
   "source": [
    "res = train_test_split(data, labels, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42,\n",
    "                       stratify=labels)\n",
    "train_data, test_data, train_labels, test_labels = res \n",
    "\n",
    "# np.bincount expects non negative integers:\n",
    "print('All:', np.bincount(labels.astype(int))  / float(len(labels)) * 100.0)\n",
    "print('Training:', np.bincount(train_labels.astype(int)) / float(len(train_labels)) * 100.0)\n",
    "print('Test:', np.bincount(test_labels.astype(int)) / float(len(test_labels)) * 100.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
